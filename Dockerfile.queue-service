# =============================================================================
# Dockerfile para Cloud Run Service - Queue Worker Persistente
# Corre queue:work continuamente con restart automático
# IMPORTANTE: Cloud Run Services requieren responder en puerto 8080
# =============================================================================

FROM php:8.3-cli-alpine

# Instalar dependencias del sistema
RUN apk add --no-cache \
    postgresql-dev \
    libpng-dev \
    libzip-dev \
    zip \
    unzip \
    supervisor \
    busybox-extras

# Instalar extensiones PHP
RUN docker-php-ext-install pdo pdo_pgsql pgsql zip gd bcmath pcntl

# Instalar Composer
COPY --from=composer:latest /usr/bin/composer /usr/bin/composer

WORKDIR /app

# Copiar archivos de composer primero (para cache de layers)
COPY composer.json composer.lock ./

# Instalar dependencias (sin dev)
RUN composer install --no-dev --no-scripts --no-autoloader --prefer-dist --ignore-platform-reqs

# Copiar el resto del código
COPY . .

# Generar autoloader optimizado
RUN composer dump-autoload --optimize

# =============================================================================
# Configuración de Supervisor
# - 2 workers de queue en paralelo
# - 1 proceso de recovery cada 60s
# - 1 servidor HTTP para health checks (REQUERIDO por Cloud Run)
# =============================================================================
RUN mkdir -p /etc/supervisor.d /var/log

COPY <<'EOF' /etc/supervisor.d/queue-worker.ini
[program:queue-worker]
process_name=%(program_name)s_%(process_num)02d
command=php /app/artisan queue:work database --sleep=3 --tries=3 --timeout=3600 --memory=1536
autostart=true
autorestart=true
stopasgroup=true
killasgroup=true
; IMPORTANTE: 1 worker para evitar problemas de concurrencia con el cache de prospectos
; Cuando 2 workers procesan archivos grandes en paralelo, sus caches no se sincronizan
; y puede haber problemas de memoria (2GB limite de Cloud Run)
numprocs=1
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
stderr_logfile=/dev/stderr
stderr_logfile_maxbytes=0
stopwaitsecs=3600

[program:recovery]
process_name=%(program_name)s
command=sh -c 'while true; do php /app/artisan importaciones:recover --quiet 2>/dev/null || true; sleep 60; done'
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0

[program:healthcheck-server]
process_name=%(program_name)s
command=php -S 0.0.0.0:8080 /app/health-server.php
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/dev/stdout
stdout_logfile_maxbytes=0
EOF

# =============================================================================
# Health check server para Cloud Run
# Cloud Run MATA el container si no responde en puerto 8080
# =============================================================================
COPY <<'HEALTH' /app/health-server.php
<?php
// Simple router para health checks
$uri = $_SERVER['REQUEST_URI'] ?? '/';

// Health endpoint
if ($uri === '/' || $uri === '/health' || $uri === '/healthz') {
    header('Content-Type: application/json');
    http_response_code(200);
    
    // Verificar que los workers están corriendo
    $workers = shell_exec('pgrep -f "queue:work" | wc -l');
    $workerCount = (int) trim($workers);
    
    echo json_encode([
        'status' => 'healthy',
        'service' => 'nurturing-queue-worker',
        'workers_running' => $workerCount,
        'timestamp' => date('c'),
        'uptime' => file_exists('/tmp/start_time') 
            ? (time() - (int)file_get_contents('/tmp/start_time')) . 's'
            : 'unknown'
    ]);
    exit;
}

// Cualquier otra ruta
http_response_code(404);
echo json_encode(['error' => 'Not found']);
HEALTH

# =============================================================================
# Script de entrada
# =============================================================================
COPY <<'ENTRYPOINT' /entrypoint.sh
#!/bin/sh
set -e

echo "=============================================="
echo "=== Cloud Run Service: Queue Worker v3.1  ==="
echo "=== Persistent Worker con Auto-Recovery   ==="
echo "=============================================="
echo "Timestamp: $(date -Iseconds)"
echo ""

# Guardar timestamp de inicio
date +%s > /tmp/start_time

# Ejecutar recovery inicial
echo "[INIT] Ejecutando recovery inicial..."
php artisan importaciones:recover || echo "WARN: Recovery inicial falló (puede ser normal en primer deploy)"
echo ""

echo "[START] Iniciando Supervisor con:"
echo "  - 2x queue:work (procesamiento paralelo)"
echo "  - 1x recovery loop (cada 60 segundos)"
echo "  - 1x health server (puerto 8080)"
echo "=============================================="

# Iniciar supervisor en foreground
exec /usr/bin/supervisord -n -c /etc/supervisord.conf
ENTRYPOINT

RUN chmod +x /entrypoint.sh

# Configuración base de supervisor
RUN echo -e "[supervisord]\nnodaemon=true\nlogfile=/dev/null\nlogfile_maxbytes=0\npidfile=/tmp/supervisord.pid\n\n[include]\nfiles = /etc/supervisor.d/*.ini" > /etc/supervisord.conf

# Puerto para Cloud Run (OBLIGATORIO)
EXPOSE 8080

# Comando por defecto
ENTRYPOINT ["/entrypoint.sh"]
